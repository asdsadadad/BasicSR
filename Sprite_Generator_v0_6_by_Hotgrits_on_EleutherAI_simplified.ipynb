{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sprite_Generator_v0_6_Breadsticks.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sEX3N-Qwhsjb",
        "6jEMkq_2hE6f",
        "Hd6_zISfh0HK",
        "WS1xG2mvh5jh",
        "87EmMx5Kh9P7",
        "HZ9KdWKxjhDs",
        "aU9A9IVjiE0a"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asdsadadad/BasicSR/blob/master/Sprite_Generator_v0_6_by_Hotgrits_on_EleutherAI_simplified.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7K8s5Ddlzpy",
        "outputId": "ee0625b7-ecb9-4681-98a5-4c91bb6e7a79",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Oct  6 00:46:10 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sEX3N-Qwhsjb"
      },
      "source": [
        "## Run this (you only need to do this once per session)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mYzQ_NNalzTm",
        "outputId": "b3890d8a-c0b4-43b0-dd89-274f16f6e2d6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!curl -L -o sprite_generator_v06_6.pt -C - 'https://cdn.discordapp.com/attachments/730484623028519072/867593206220718112/sprite_generator_v06_7-21-2021_7.pt'\n",
        "!pip -qq install torch_optimizer\n",
        "!pip -qq install av\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as T\n",
        "import torchvision.transforms.functional as TF\n",
        "import torch_optimizer as optim\n",
        "import PIL\n",
        "from PIL import Image\n",
        "import random\n",
        "import math\n",
        "import gc\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "def clear_mem():\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "ToTensor = T.ToTensor()\n",
        "ToImage  = T.ToPILImage()\n",
        "\n",
        "def OpenImage(x, resize=None, convert=\"RGB\"):\n",
        "    if resize:\n",
        "        return ToTensor(Image.open(x).convert(convert).resize(resize)).unsqueeze(0).to(device)\n",
        "    else:\n",
        "        return ToTensor(Image.open(x).convert(convert)).unsqueeze(0).to(device)\n",
        "\n",
        "def diff_abs(x, y=0.0001):\n",
        "    return torch.sqrt(x*x+y)\n",
        "\n",
        "def diff_relu(x, y=0.0001):\n",
        "    return (torch.sqrt(x*x+y)+x)*0.5\n",
        "\n",
        "def diff_clamp(x, y=0.0001):\n",
        "    return diff_relu(1-diff_relu(1-x, y), y)\n",
        "\n",
        "class PixelNet(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(PixelNet, self).__init__()\n",
        "\n",
        "        self.enc_layers_0 = nn.Sequential(\n",
        "                              nn.Conv2d( 1,  8, 2, 2, 0),\n",
        "                              nn.Conv2d( 8, 16, 2, 2, 0),\n",
        "                              nn.Conv2d(16, 32, 2, 2, 0),\n",
        "                        )\n",
        "\n",
        "        self.batchnorm = nn.InstanceNorm2d(32)\n",
        "\n",
        "        self.lin_layers = nn.Sequential(\n",
        "                              nn.Conv2d(32, 64, 3, 1, 1),\n",
        "                              nn.BatchNorm2d(64),\n",
        "                              nn.GELU(),\n",
        "                              nn.Conv2d(64, 64, 3, 1, 1),\n",
        "                              nn.BatchNorm2d(64),\n",
        "                              nn.GELU(),\n",
        "                              nn.Conv2d(64, 32, 3, 1, 1),\n",
        "                              nn.BatchNorm2d(32),\n",
        "                          )\n",
        "\n",
        "        self.cnn_layers = nn.Sequential(\n",
        "                              nn.Conv2d(32, 32, 3, 1, 1),      \n",
        "                              nn.ConvTranspose2d(32, 16, 2, 2),\n",
        "                              nn.Conv2d(16, 32, 3, 1, 1),      \n",
        "                              nn.BatchNorm2d(32),              \n",
        "                              nn.GELU(),                       \n",
        "                              nn.ConvTranspose2d(32, 16, 2, 2),\n",
        "                              nn.Conv2d(16, 32, 3, 1, 1),      \n",
        "                              nn.BatchNorm2d(32),              \n",
        "                              nn.GELU(),                       \n",
        "                              nn.ConvTranspose2d(32, 16, 2, 2),\n",
        "                              nn.Conv2d(16, 4, 3, 1, 1),       \n",
        "                          )\n",
        "\n",
        "        self.palette = torch.tensor([[0.0, 0.333, 0.667, 1.0]]).T.to(device)\n",
        "\n",
        "    def encode(self, x):\n",
        "        x = self.enc_layers_0(x)\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, y=25, batchnorm=True, dropout_p=0):\n",
        "        if dropout_p == 0:\n",
        "            dropout = nn.Identity()\n",
        "        else:\n",
        "            dropout = nn.AlphaDropout(dropout_p)\n",
        "        if batchnorm == True:\n",
        "            x = self.batchnorm(x)\n",
        "        # x = self.lin_layers(x)\n",
        "        # x = self.cnn_layers(x)\n",
        "        x = self.lin_layers[:3](x)\n",
        "        x = dropout(x)\n",
        "        x = self.lin_layers[3:6](x)\n",
        "        x = self.lin_layers[6:](x)\n",
        "        x = dropout(x)\n",
        "        x = self.cnn_layers[0](x)\n",
        "        x = dropout(x)\n",
        "        x = self.cnn_layers[1:](x)\n",
        "        x = (x.permute(0,2,3,1).mul(y).softmax(-1) @ self.palette).permute(0,3,1,2)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x, y=25):\n",
        "        x = self.encode(x)\n",
        "        x = self.decode(x, y)\n",
        "        return x\n",
        "\n",
        "model = PixelNet().to(device)\n",
        "\n",
        "# model(torch.rand(8,1,56,56).to(device)).shape\n",
        "\n",
        "model.load_state_dict(torch.load(\"/content/sprite_generator_v06_6.pt\"))\n",
        "model.eval();\n",
        "!pip install --no-deps git+https://github.com/openai/CLIP.git\n",
        "!pip install --no-deps ftfy regex tqdm\n",
        "\n",
        "import clip\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.set_grad_enabled(False)\n",
        "\n",
        "perceptor, preprocess = clip.load(\"ViT-B/32\", jit=False)\n",
        "perceptor.eval().float().requires_grad_(False);\n",
        "\n",
        "CLIP_Normalization = T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711))\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  416k  100  416k    0     0  1375k      0 --:--:-- --:--:-- --:--:-- 1371k\n",
            "\u001b[K     |████████████████████████████████| 72 kB 515 kB/s \n",
            "\u001b[K     |████████████████████████████████| 37.2 MB 31 kB/s \n",
            "\u001b[?25hCollecting git+https://github.com/openai/CLIP.git\n",
            "  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-lk5y75d1\n",
            "  Running command git clone -q https://github.com/openai/CLIP.git /tmp/pip-req-build-lk5y75d1\n",
            "Building wheels for collected packages: clip\n",
            "  Building wheel for clip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for clip: filename=clip-1.0-py3-none-any.whl size=1369090 sha256=9ad51f0e5215d09725256107c0e8693c587b0089d095ad670c3faa7e08eebdad\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-i00xrp5s/wheels/fd/b9/c3/5b4470e35ed76e174bff77c92f91da82098d5e35fd5bc8cdac\n",
            "Successfully built clip\n",
            "Installing collected packages: clip\n",
            "Successfully installed clip-1.0\n",
            "Collecting ftfy\n",
            "  Downloading ftfy-6.0.3.tar.gz (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 1.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.62.3)\n",
            "Building wheels for collected packages: ftfy\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=85fd8caed418b4fe488763c5d82e90f5dc2320aea277c4bc944341417c303c21\n",
            "  Stored in directory: /root/.cache/pip/wheels/19/f5/38/273eb3b5e76dfd850619312f693716ac4518b498f5ffb6f56d\n",
            "Successfully built ftfy\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.0.3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 338M/338M [00:17<00:00, 20.3MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJXtXU26DvyE"
      },
      "source": [
        "## Generate the image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VSr_fENSD8Sc"
      },
      "source": [
        "Set the prompt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efbhY8zgD8Dc"
      },
      "source": [
        "prompt = perceptor.encode_text(clip.tokenize([\"Metal Gear Solid\"]).to(device)).mean(0,True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0gzOyHbD7r8"
      },
      "source": [
        "Or use an image as a prompt instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AdzyVoWjD7ES",
        "outputId": "191ab1f3-5a41-4f47-9d0e-826299016720",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 362
        }
      },
      "source": [
        "prompt_img = OpenImage(\"flickr_dog_000137.jpg\", (224,224)).tile(8,1,1,1)\n",
        "prompt_img += torch.randn_like(prompt_img) * 0.025\n",
        "prompt = perceptor.encode_image(CLIP_Normalization(prompt_img)).mean(0,True)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-e999d580f37e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprompt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOpenImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"flickr_dog_000137.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprompt_img\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m0.025\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperceptor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCLIP_Normalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-09413abbdf3b>\u001b[0m in \u001b[0;36mOpenImage\u001b[0;34m(x, resize, convert)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mOpenImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2842\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2843\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2844\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2845\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'flickr_dog_000137.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XkQiJb4Ekbl"
      },
      "source": [
        "Then press Play here to generate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKFR7EvHkN6-",
        "outputId": "7888402b-0a5e-4799-9da0-22001879f089",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 741
        }
      },
      "source": [
        "# Vignettes for init images and masking noise\n",
        "vig = torch.cat(torch.meshgrid(2*[torch.linspace(-1,1,64)])).reshape(2,64,64).pow(2).sum(0,True).mul(2).sub(0).clamp(0,1).to(device)\n",
        "vig = TF.crop(vig, 0, 4, 56, 56).unsqueeze(0)\n",
        "vig_7x7 = torch.cat(torch.meshgrid(2*[torch.linspace(-1,1,9)])).reshape(2,9,9).pow(2).sum(0,True).mul(3).sub(1).clamp(0,1).to(device)\n",
        "vig_7x7 = 1 - TF.crop(vig_7x7, 0, 1, 7, 7)\n",
        "\n",
        "blank_image = model.encode(vig - torch.rand_like(vig) * 0.333)\n",
        "blank_image = model.batchnorm(blank_image) # The encoder's values are huge due to the batchnorm being in the decoder section, but for easier optimization batchnorm it first.\n",
        "clip_root = blank_image.clone().detach() + torch.randn((1,32,7,7)).to(device).mul(vig_7x7) * 0.25\n",
        "clip_root = clip_root.requires_grad_(True)\n",
        "clip_optimizer = optim.Yogi([clip_root], lr=1/8, weight_decay=0.00)\n",
        "\n",
        "video_frames = None\n",
        "\n",
        "torch.set_grad_enabled(True)\n",
        "model.eval()\n",
        "\n",
        "vig = torch.cat(torch.meshgrid(2*[torch.linspace(-1,1,64)])).reshape(2,64,64).pow(2).sum(0,True).mul(3).sub(1).clamp(0,1).pow(2).to(device)\n",
        "vig = TF.crop(vig, 0, 4, 56, 56)\n",
        "\n",
        "laplacian_kernel = torch.tensor([\n",
        "    [.05, .2, .05],\n",
        "    [ .2, -1, .2 ],\n",
        "    [.05, .2, .05]\n",
        "]).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "def laplacian_filter(x):\n",
        "    b, c, h, w = x.shape\n",
        "    x = x.reshape(b*c, 1, h, w)\n",
        "    x = F.pad(x, [2,2,2,2], mode='reflect')\n",
        "    x = F.conv2d(x, laplacian_kernel)\n",
        "    x = TF.pad(x, -1)\n",
        "    b2, c2, h2, w2 = x.shape\n",
        "    x = x.reshape(b, c, h2, w2)\n",
        "    return x\n",
        "\n",
        "def white_background_check(x):\n",
        "    x = 1 - x\n",
        "    x = x * vig\n",
        "    x_mean = x.mean()\n",
        "    x_std = x.std()\n",
        "    return x_mean + x_std\n",
        "\n",
        "def sneaky_round(x):\n",
        "    new_x = x\n",
        "    with torch.no_grad():\n",
        "      new_x[:] = x.mul(3).round().div(3)\n",
        "    return new_x\n",
        "\n",
        "augments = T.Compose([\n",
        "        T.RandomChoice([\n",
        "            T.Resize((224,224), T.InterpolationMode.NEAREST),\n",
        "            T.Resize((224,224), T.InterpolationMode.BILINEAR),\n",
        "            T.Resize((240,224), T.InterpolationMode.NEAREST),\n",
        "            T.Resize((240,224), T.InterpolationMode.BILINEAR),\n",
        "            T.Resize((256,224), T.InterpolationMode.NEAREST),\n",
        "            T.Resize((256,224), T.InterpolationMode.BILINEAR),\n",
        "            T.Resize((224,240), T.InterpolationMode.NEAREST),\n",
        "            T.Resize((224,240), T.InterpolationMode.BILINEAR),\n",
        "            T.Resize((224,256), T.InterpolationMode.NEAREST),\n",
        "            T.Resize((224,256), T.InterpolationMode.BILINEAR),\n",
        "        ]),\n",
        "        T.Pad(64, fill=1.0),\n",
        "        T.RandomRotation(15, T.InterpolationMode.BILINEAR),\n",
        "        T.Pad(-56),\n",
        "        T.RandomChoice([\n",
        "            T.Lambda(lambda x: TF.gaussian_blur(x, 7, 2.55)),\n",
        "            T.Lambda(lambda x: TF.gaussian_blur(x, 5, 1.27)),\n",
        "            T.Lambda(lambda x: TF.gaussian_blur(x, 3, 0.64)),\n",
        "            T.Lambda(lambda x: x),\n",
        "        ]),\n",
        "        T.Lambda(lambda x: x + torch.rand(1,).item() * 0.2 - 0.1),\n",
        "        T.Lambda(lambda x: x * (torch.rand(1,).item() * 0.3 + 0.85)),\n",
        "        T.RandomCrop((224,224)),\n",
        "        T.Lambda(lambda x: x + torch.randn_like(x).mul(0.02)),\n",
        "        T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
        "])\n",
        "\n",
        "gentle_augments = T.Compose([\n",
        "        T.RandomChoice([\n",
        "            T.Resize((224,224), T.InterpolationMode.NEAREST),\n",
        "            T.Resize((224,224), T.InterpolationMode.BILINEAR),\n",
        "        ]),\n",
        "        T.Pad(16, fill=1.0),\n",
        "        T.RandomRotation(2, T.InterpolationMode.BILINEAR),\n",
        "        T.Pad(-12),\n",
        "        T.RandomChoice([\n",
        "            T.Lambda(lambda x: TF.gaussian_blur(x, 7, 2.55)),\n",
        "            T.Lambda(lambda x: TF.gaussian_blur(x, 5, 1.27)),\n",
        "            T.Lambda(lambda x: TF.gaussian_blur(x, 3, 0.64)),\n",
        "            T.Lambda(lambda x: x),\n",
        "        ]),\n",
        "        T.Lambda(lambda x: x + torch.rand(1,).item() * 0.2 - 0.1),\n",
        "        T.Lambda(lambda x: x * (torch.rand(1,).item() * 0.3 + 0.85)),\n",
        "        T.RandomCrop((224,224)),\n",
        "        T.Lambda(lambda x: x + torch.randn_like(x).mul(0.02)),\n",
        "        T.Normalize((0.48145466, 0.4578275, 0.40821073), (0.26862954, 0.26130258, 0.27577711)),\n",
        "])\n",
        "\n",
        "for i in range(500):\n",
        "    x = model.decode(clip_root)\n",
        "    x_color = x.tile(1,3,1,1)\n",
        "\n",
        "    with torch.no_grad(): #This is just preparing frames for the video. It stores them in ram, not gpu memory, so it shouldn't impact much.\n",
        "        x_color_big = TF.resize(x_color, (112,112), T.InterpolationMode.NEAREST)\n",
        "        x_color_big = F.interpolate(x_color_big, (224,224), mode='bicubic', align_corners=False)\n",
        "        if video_frames == None:\n",
        "            video_frames = (x_color_big.permute(0,2,3,1).clamp(0,1)*255).byte().cpu()\n",
        "        else:\n",
        "            video_frames = torch.cat([video_frames, (x_color_big.permute(0,2,3,1).clamp(0,1)*255).byte().cpu()])\n",
        "\n",
        "    x_aug = torch.cat([augments(x_color) for _ in range(16)])\n",
        "    x_enc = perceptor.encode_image(x_aug)\n",
        "    comparisons = 1.0 - torch.cosine_similarity(prompt, x_enc, -1)\n",
        "    loss  = torch.mean(comparisons)\n",
        "    loss += (x - torch.round(x*3).div(3)).pow(2).mean() * 0.25\n",
        "    loss += white_background_check(x).mul(2).pow(2) * 0.25\n",
        "    loss += laplacian_filter(x).mean().pow(4)\n",
        "    with torch.no_grad():\n",
        "        loss.backward()\n",
        "        # clip_root.grad = TF.gaussian_blur(clip_root.grad, 3) * 0.25 + clip_root.grad * 0.75\n",
        "        clip_root.grad /= clip_root.grad.norm().add(1e-8)\n",
        "        clip_optimizer.step()\n",
        "        clip_optimizer.zero_grad()\n",
        "        if i % 100 == 0:\n",
        "            print(i, loss.item())\n",
        "            display(ToImage(x.clamp(0,1)[0]).resize((224,224),0))\n",
        "\n",
        "x = model.decode(clip_root)\n",
        "display(ToImage(x.clamp(0,1)[0]).resize((224,224),0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 0.8090600371360779\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x224 at 0x7F32A6E32050>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 0.6680757999420166\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x224 at 0x7F32A6E38D10>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200 0.6427553296089172\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<PIL.Image.Image image mode=L size=224x224 at 0x7F32A6E32050>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kcZ3MaAri9PL"
      },
      "source": [
        "Write video of generation process"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHByhFjc1V5R"
      },
      "source": [
        "torchvision.io.write_video(\"lr_100.mp4\", video_frames, fps=15, options={'crf': '30'})"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}